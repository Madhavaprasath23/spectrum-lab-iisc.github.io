{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e78670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "950ecdd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Saved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(v)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mentries.values())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m entries to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Run it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[43mfetch_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1g1i1B4AAAAJ\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pubs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mfetch_and_save\u001b[39m\u001b[34m(user_id, output_file, max_pubs)\u001b[39m\n\u001b[32m     88\u001b[39m filled = scholarly.fill(pub)\n\u001b[32m     89\u001b[39m et = guess_entry_type(filled)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m bibtex = \u001b[43mformat_bibtex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43met\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m entries[et].append(bibtex)\n\u001b[32m     92\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✔ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00met\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilled[\u001b[33m'\u001b[39m\u001b[33mbib\u001b[39m\u001b[33m'\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mformat_bibtex\u001b[39m\u001b[34m(pub, entry_type)\u001b[39m\n\u001b[32m     54\u001b[39m month = bib.get(\u001b[33m'\u001b[39m\u001b[33mpub_month\u001b[39m\u001b[33m'\u001b[39m, datetime.now().month)\n\u001b[32m     56\u001b[39m journal = bib.get(\u001b[33m'\u001b[39m\u001b[33mjournal\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m booktitle = bib.get(\u001b[33m'\u001b[39m\u001b[33mbooktitle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfetch_booktitle_via_crossref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m first_author = authors.split(\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m].split()[-\u001b[32m1\u001b[39m]\n\u001b[32m     60\u001b[39m first_word = extract_first_word(title)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mfetch_booktitle_via_crossref\u001b[39m\u001b[34m(title, year, retries, delay)\u001b[39m\n\u001b[32m     29\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://api.crossref.org/works\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m params = {\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquery.title\u001b[39m\u001b[33m\"\u001b[39m: title,\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfrom-pub-date:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,until-pub-date:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m resp = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m resp.raise_for_status()\n\u001b[32m     37\u001b[39m data = resp.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spectrum-website/.venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1423\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1422\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1425\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from scholarly import scholarly\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def sanitize_key(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n",
    "    return re.sub(r'\\W+', '', text)\n",
    "\n",
    "def extract_first_word(title):\n",
    "    words = re.findall(r'\\b\\w+\\b', title)\n",
    "    return sanitize_key(words[0]) if words else \"Untitled\"\n",
    "\n",
    "def guess_entry_type(pub):\n",
    "    bib = pub.get('bib', {})\n",
    "    if 'journal' in bib:\n",
    "        return 'article'\n",
    "    elif 'title' in bib:\n",
    "        return 'inproceedings'\n",
    "    else:\n",
    "        return 'misc'\n",
    "\n",
    "def fetch_booktitle_via_crossref(title, year, retries=7, delay=3):\n",
    "    \"\"\"Try CrossRef up to `retries` times with exponential backoff on timeout.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            url = \"https://api.crossref.org/works\"\n",
    "            params = {\n",
    "                \"query.title\": title,\n",
    "                \"rows\": 1,\n",
    "                \"filter\": f\"from-pub-date:{year},until-pub-date:{year}\"\n",
    "            }\n",
    "            resp = requests.get(url, params=params, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            items = data.get(\"message\", {}).get(\"items\", [])\n",
    "            if items:\n",
    "                container = items[0].get(\"container-title\", [])\n",
    "                return container[0] if container else \"\"\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ CrossRef error (attempt {attempt+1}/{retries}) for '{title}': {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay * (2 ** attempt))  # exponential backoff\n",
    "    return \"\"\n",
    "\n",
    "def format_bibtex(pub, entry_type):\n",
    "    bib = pub.get('bib', {})\n",
    "    title = bib.get('title', 'Unknown Title')\n",
    "    authors = bib.get('author', 'Unknown Author')\n",
    "    year = bib.get('pub_year', '????')\n",
    "    month = bib.get('pub_month', datetime.now().month)\n",
    "\n",
    "    journal = bib.get('journal', '')\n",
    "    booktitle = bib.get('booktitle', '') or fetch_booktitle_via_crossref(title, year)\n",
    "\n",
    "    first_author = authors.split(' and ')[0].split()[-1]\n",
    "    first_word = extract_first_word(title)\n",
    "    key = f\"{first_author}{year}{first_word}\"\n",
    "\n",
    "    lines = [f\"@{entry_type}{{{key},\",\n",
    "             f\"  author = {{{authors}}},\",\n",
    "             f\"  title = {{{title}}},\"]\n",
    "\n",
    "    if entry_type == 'inproceedings' and booktitle:\n",
    "        lines.append(f\"  booktitle = {{{booktitle}}},\")\n",
    "    if entry_type == 'article' and journal:\n",
    "        lines.append(f\"  journal = {{{journal}}},\")\n",
    "\n",
    "    lines.extend([\n",
    "        f\"  month = {{{month}}},\",\n",
    "        f\"  year = {{{year}}},\",\n",
    "        f\"  bibtex_show = {{true}}\",\n",
    "        f\"}}\\n\"\n",
    "    ])\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def fetch_and_save(user_id, output_file='scholar.bib', max_pubs=None):\n",
    "    author = scholarly.search_author_id(user_id)\n",
    "    author = scholarly.fill(author, sections=['publications'])\n",
    "    entries = {'article': [], 'inproceedings': [], 'misc': []}\n",
    "\n",
    "    for i, pub in enumerate(author['publications']):\n",
    "        if max_pubs and i >= max_pubs:\n",
    "            break\n",
    "        filled = scholarly.fill(pub)\n",
    "        et = guess_entry_type(filled)\n",
    "        bibtex = format_bibtex(filled, et)\n",
    "        entries[et].append(bibtex)\n",
    "        print(f\"✔ {et}: {filled['bib'].get('title', '')}\")\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for et in ['article', 'inproceedings', 'misc']:\n",
    "            if entries[et]:\n",
    "                f.write(f\"% === {et.upper()} ===\\n\\n\")\n",
    "                f.writelines(entries[et])\n",
    "\n",
    "    print(f\"\\n✅ Saved {sum(len(v) for v in entries.values())} entries to {output_file}\")\n",
    "\n",
    "# Run it\n",
    "fetch_and_save('1g1i1B4AAAAJ', max_pubs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552aeae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98e035ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Loaded 292 entries from css.bib\n",
      "🚀 Processing entries with DBLP in parallel...\n",
      "🔍 DBLP search for 'Analog Communication' returned 5 hits\n",
      "🔍 DBLP search for 'IEEE Signal Processing Society' returned 5 hits\n",
      "🔍 DBLP search for 'AN EFFICIENT FULLY CONNECTED NEURAL NETWORK FOR MICROANEURYSM DETECTION FROM RETINAL FUNDUS IMAGES' returned 0 hits\n",
      "🔍 DBLP search for 'Spider GAN: Leveraging Friendly Neighbors to Accelerate GAN Training Supporting Document' returned 0 hits\n",
      "🔍 DBLP search for 'Classification of Abnormalities in WCE' returned 0 hits\n",
      "🔍 DBLP search for 'Teaching a GAN What Not to Learn (Supplementary Material)' returned 0 hits\n",
      "🔍 DBLP search for 'Denoising Enhances Visualization of Optical Coherence Tomography Images' returned 0 hits\n",
      "🔍 DBLP search for 'SAMIR: SPARSITY AMPLIFIED BEAMFORMING FOR HIGH-RESOLUTION ULTRASOUND IMAGING' returned 0 hits\n",
      "🔍 DBLP search for 'High Precision Target Localization Using a Sub-Nyquist Super-Resolution Radar' returned 0 hits\n",
      "🔍 DBLP search for 'Accelerated Diffusion using Closed-form Discriminator Guidance' returned 0 hits\n",
      "🔍 DBLP search for 'Language Understanding and Computational Semantics Cross-Language Neural Dialog State Tracker for Large Ontologies Using Hierarchical Attention.................................' returned 0 hits\n",
      "🔍 DBLP search for 'E9 213: Time-Frequency Analysis' returned 0 hits\n",
      "🔍 DBLP search for 'Audio and Acoustic Signal Processing Frequency-Domain Volterra Filter Based on Data-Driven Soft Decision for Nonlinear Acoustic Echo Suppression......' returned 0 hits\n",
      "🔍 DBLP search for 'IEEE SIGNAL PROCESSING SOCIETY' returned 5 hits\n",
      "🔍 DBLP search for 'On Multiple-Input Multiple-Output OFDM with Index Modulation for Next Generation Wireless Networks.... E. Basar 3868' returned 1 hits\n",
      "🔍 DBLP search for 'Learning Transforms With a Specified Condition Number' returned 0 hits\n",
      "🔍 DBLP search for 'Two-Dimensional FRI Signal Reconstruction Using Blind Deconvolution' returned 0 hits\n",
      "🔍 DBLP search for 'IEEE SIGNAL PROCESSING SOCIETY' returned 5 hits\n",
      "🔍 DBLP search for 'Fractional Hilbert Transform Pair of Wavelets' returned 0 hits\n",
      "🔍 DBLP search for 'General Co-Chairs A. Chockalingam, IISc Bangalore, India Navin Kashyap, IISc Bangalore, India TPC Co-Chairs Chandra R. Murthy, IISc Bangalore, India' returned 0 hits\n",
      "🔍 DBLP search for 'Fixed-Point Algorithms for Sparse-Signal Phase Retrieval' returned 0 hits\n",
      "\n",
      "✅ Written to converted.bib: 1 inproceedings, 271 articles, 20 misc\n"
     ]
    }
   ],
   "source": [
    "import bibtexparser\n",
    "import re, unicodedata, urllib.parse, requests, difflib, concurrent.futures\n",
    "\n",
    "def sanitize_key(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n",
    "    return re.sub(r'\\W+', '', text)\n",
    "\n",
    "def extract_first_word(title):\n",
    "    words = re.findall(r'\\b\\w+\\b', title)\n",
    "    return sanitize_key(words[0]) if words else \"Untitled\"\n",
    "\n",
    "def fetch_dblp_match_info(title, max_hits=5, threshold=0.85):\n",
    "    q = urllib.parse.quote(title)\n",
    "    url = f\"https://dblp.org/search/publ/api?q={q}&h={max_hits}&format=json\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10).json()\n",
    "        hits = resp.get('result', {}).get('hits', {}).get('hit', [])\n",
    "        print(f\"🔍 DBLP search for '{title}' returned {len(hits)} hits\")\n",
    "        if not hits:\n",
    "            return None\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        for hit in hits:\n",
    "            candidate_title = hit['info'].get('title', '')\n",
    "            score = difflib.SequenceMatcher(None, candidate_title.lower(), title.lower()).ratio()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = hit\n",
    "        if best_match and best_score >= threshold:\n",
    "            return best_match['info']\n",
    "    except Exception as e:\n",
    "        print(f\"❌ DBLP lookup failed for '{title}': {e}\")\n",
    "    return None\n",
    "\n",
    "def format_inproceedings_custom(entry, match_info):\n",
    "    title = entry.get('title', 'Unknown Title')\n",
    "    authors = entry.get('author', 'Unknown Author')\n",
    "    year = entry.get('year', '????')\n",
    "    month = '7'  # guess or override as needed\n",
    "\n",
    "    first_author = authors.split(' and ')[0].split()[-1]\n",
    "    first_word = extract_first_word(title)\n",
    "    key = f\"{first_author}{year}{first_word}\"\n",
    "\n",
    "    venue = match_info.get('venue', '')\n",
    "    booktitle = match_info.get('booktitle', '') or venue\n",
    "    pages = match_info.get('pages', '')\n",
    "    doi = match_info.get('doi', '')\n",
    "    ee = match_info.get('ee', '')\n",
    "    conf_abbr = match_info.get('key', '').split('/')[1].upper() if '/' in match_info.get('key', '') else 'CONF'\n",
    "    eventdate = f\"{year}-07-19\"\n",
    "\n",
    "    return f\"\"\"@inproceedings{{{key},\n",
    "  author = {{{authors}}},\n",
    "  booktitle = {{{booktitle}}},\n",
    "  title = {{{title}}},\n",
    "  venue = {{{venue}}},\n",
    "  eventdate = {{{eventdate}}},\n",
    "  month = {{{month}}},\n",
    "  year = {{{year}}},\n",
    "  openreview = {{{ee}}},\n",
    "  bibtex_show = {{true}},\n",
    "  ABBR = {{{conf_abbr}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "def format_article(entry):\n",
    "    title = entry.get('title', 'Unknown')\n",
    "    authors = entry.get('author', 'Unknown Author')\n",
    "    year = entry.get('year', '????')\n",
    "    journal = entry.get('journal', '')\n",
    "    month = '7'\n",
    "    abbr = journal.split()[0].upper() if journal else \"JOUR\"\n",
    "    key = f\"{authors.split(' and ')[0].split()[-1]}{year}{extract_first_word(title)}\"\n",
    "\n",
    "    return f\"\"\"@article{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  journal = {{{journal}}},\n",
    "  month = {{{month}}},\n",
    "  year = {{{year}}},\n",
    "  bibtex_show = {{true}},\n",
    "  ABBR = {{{abbr}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "def format_misc(entry):\n",
    "    title = entry.get('title', 'Unknown')\n",
    "    authors = entry.get('author', 'Unknown Author')\n",
    "    year = entry.get('year', '????')\n",
    "    month = '7'\n",
    "    key = f\"{authors.split(' and ')[0].split()[-1]}{year}{extract_first_word(title)}\"\n",
    "    return f\"\"\"@misc{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  month = {{{month}}},\n",
    "  year = {{{year}}},\n",
    "  bibtex_show = {{true}},\n",
    "  ABBR = {{MISC}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "def process_entry(entry):\n",
    "    title = entry.get('title', '')\n",
    "    if 'journal' in entry:\n",
    "        return 'article', format_article(entry)\n",
    "    match_info = fetch_dblp_match_info(title)\n",
    "    if match_info:\n",
    "        return 'inproceedings', format_inproceedings_custom(entry, match_info)\n",
    "    return 'misc', format_misc(entry)\n",
    "\n",
    "def process_bib_file(input_file='css.bib', output_file='converted.bib'):\n",
    "    with open(input_file, 'r', encoding='utf-8') as bibtex_file:\n",
    "        bib_database = bibtexparser.load(bibtex_file)\n",
    "\n",
    "    print(f\"📚 Loaded {len(bib_database.entries)} entries from {input_file}\")\n",
    "    entries = bib_database.entries\n",
    "\n",
    "    # Run in parallel\n",
    "    print(\"🚀 Processing entries with DBLP in parallel...\")\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(executor.map(process_entry, entries))\n",
    "\n",
    "    # Collect formatted BibTeX\n",
    "    articles, inprocs, miscs = [], [], []\n",
    "    for typ, entry in results:\n",
    "        if typ == 'article':\n",
    "            articles.append(entry)\n",
    "        elif typ == 'inproceedings':\n",
    "            inprocs.append(entry)\n",
    "        else:\n",
    "            miscs.append(entry)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        if inprocs:\n",
    "            f.write(\"% === INPROCEEDINGS ===\\n\\n\")\n",
    "            f.writelines(inprocs)\n",
    "        if articles:\n",
    "            f.write(\"% === ARTICLES ===\\n\\n\")\n",
    "            f.writelines(articles)\n",
    "        if miscs:\n",
    "            f.write(\"% === MISC ===\\n\\n\")\n",
    "            f.writelines(miscs)\n",
    "\n",
    "    print(f\"\\n✅ Written to {output_file}: {len(inprocs)} inproceedings, {len(articles)} articles, {len(miscs)} misc\")\n",
    "\n",
    "# Run the converter\n",
    "process_bib_file('css.bib', 'converted.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ed3c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Loaded 292 entries from css.bib\n",
      "🚀 Processing entries with DBLP in parallel...\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Patent\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Preprint\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Preprint\n",
      "Preprint\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Book chapter\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Book chapter\n",
      "\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Preprint\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Book chapter\n",
      "Journal article\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Preprint\n",
      "Preprint\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Book chapter\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Book chapter\n",
      "Conference paper\n",
      "Preprint\n",
      "Preprint\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Preprint\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Preprint\n",
      "Preprint\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Preprint\n",
      "Preprint\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Preprint\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Book chapter\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Preprint\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Preprint\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Book chapter\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Preprint\n",
      "Preprint\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "\n",
      "Preprint\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "\n",
      "Conference paper\n",
      "Conference paper\n",
      "Preprint\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Book chapter\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "\n",
      "Book chapter\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "\n",
      "Conference paper\n",
      "Book\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "\n",
      "\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Abstract\n",
      "Preprint\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Preprint\n",
      "Book chapter\n",
      "Conference paper\n",
      "Book chapter\n",
      "Book chapter\n",
      "Preprint\n",
      "Preprint\n",
      "Preprint\n",
      "Journal article\n",
      "Conference paper\n",
      "Preprint\n",
      "Conference paper\n",
      "Conference paper\n",
      "Journal article\n",
      "Conference paper\n",
      "Journal article\n",
      "Journal article\n",
      "Conference paper\n",
      "\n",
      "Conference paper\n",
      "Conference paper\n",
      "Book chapter\n",
      "Conference paper\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "🔍 DBLP search for 'Denoising Enhances Visualization of Optical Coherence Tomography Images' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'Accelerated Diffusion using Closed-form Discriminator Guidance' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'Analog Communication' returned 5 hits\n",
      "\n",
      "🔍 DBLP search for 'High Precision Target Localization Using a Sub-Nyquist Super-Resolution Radar' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'AN EFFICIENT FULLY CONNECTED NEURAL NETWORK FOR MICROANEURYSM DETECTION FROM RETINAL FUNDUS IMAGES' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'Teaching a GAN What Not to Learn (Supplementary Material)' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'Spider GAN: Leveraging Friendly Neighbors to Accelerate GAN Training Supporting Document' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'Classification of Abnormalities in WCE' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'IEEE Signal Processing Society' returned 5 hits\n",
      "\n",
      "🔍 DBLP search for 'SAMIR: SPARSITY AMPLIFIED BEAMFORMING FOR HIGH-RESOLUTION ULTRASOUND IMAGING' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'Language Understanding and Computational Semantics Cross-Language Neural Dialog State Tracker for Large Ontologies Using Hierarchical Attention.................................' returned 0 hits\n",
      "\n",
      "🔍 DBLP search for 'Two-Dimensional FRI Signal Reconstruction Using Blind Deconvolution' returned 0 hits\n",
      "🔍 DBLP search for 'Fractional Hilbert Transform Pair of Wavelets' returned 0 hits\n",
      "🔍 DBLP search for 'Learning Transforms With a Specified Condition Number' returned 0 hits\n",
      "🔍 DBLP search for 'General Co-Chairs A. Chockalingam, IISc Bangalore, India Navin Kashyap, IISc Bangalore, India TPC Co-Chairs Chandra R. Murthy, IISc Bangalore, India' returned 0 hits\n",
      "🔍 DBLP search for 'Audio and Acoustic Signal Processing Frequency-Domain Volterra Filter Based on Data-Driven Soft Decision for Nonlinear Acoustic Echo Suppression......' returned 0 hits\n",
      "🔍 DBLP search for 'On Multiple-Input Multiple-Output OFDM with Index Modulation for Next Generation Wireless Networks.... E. Basar 3868' returned 1 hits\n",
      "🔍 DBLP search for 'E9 213: Time-Frequency Analysis' returned 0 hits\n",
      "🔍 DBLP search for 'IEEE SIGNAL PROCESSING SOCIETY' returned 5 hits\n",
      "🔍 DBLP search for 'IEEE SIGNAL PROCESSING SOCIETY' returned 5 hits\n",
      "🔍 DBLP search for 'Fixed-Point Algorithms for Sparse-Signal Phase Retrieval' returned 0 hits\n"
     ]
    }
   ],
   "source": [
    "import bibtexparser\n",
    "import re, unicodedata, urllib.parse, requests, difflib, concurrent.futures\n",
    "\n",
    "def sanitize_key(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n",
    "    return re.sub(r'\\W+', '', text)\n",
    "\n",
    "def extract_first_word(title):\n",
    "    words = re.findall(r'\\b\\w+\\b', title)\n",
    "    return sanitize_key(words[0]) if words else \"Untitled\"\n",
    "\n",
    "def fetch_dblp_match_info(title, max_hits=5, threshold=0.85):\n",
    "    q = urllib.parse.quote(title)\n",
    "    url = f\"https://dblp.org/search/publ/api?q={q}&h={max_hits}&format=json\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10).json()\n",
    "        hits = resp.get('result', {}).get('hits', {}).get('hit', [])\n",
    "        print(f\"🔍 DBLP search for '{title}' returned {len(hits)} hits\")\n",
    "        if not hits:\n",
    "            return None\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        for hit in hits:\n",
    "            candidate_title = hit['info'].get('title', '')\n",
    "            score = difflib.SequenceMatcher(None, candidate_title.lower(), title.lower()).ratio()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = hit\n",
    "        if best_match and best_score >= threshold:\n",
    "            return best_match['info']\n",
    "    except Exception as e:\n",
    "        print(f\"❌ DBLP lookup failed for '{title}': {e}\")\n",
    "    return None\n",
    "\n",
    "def format_inproceedings_custom(entry, match_info):\n",
    "    title = entry.get('title', 'Unknown Title')\n",
    "    authors = entry.get('author', 'Unknown Author')\n",
    "    year = entry.get('year', '????')\n",
    "    month = '7'  # guess or override as needed\n",
    "\n",
    "    first_author = authors.split(' and ')[0].split()[-1]\n",
    "    first_word = extract_first_word(title)\n",
    "    key = f\"{first_author}{year}{first_word}\"\n",
    "\n",
    "    venue = match_info.get('venue', '')\n",
    "    booktitle = match_info.get('booktitle', '') or venue\n",
    "    pages = match_info.get('pages', '')\n",
    "    doi = match_info.get('doi', '')\n",
    "    ee = match_info.get('ee', '')\n",
    "    conf_abbr = match_info.get('key', '').split('/')[1].upper() if '/' in match_info.get('key', '') else 'CONF'\n",
    "    eventdate = f\"{year}-07-19\"\n",
    "\n",
    "    return f\"\"\"@inproceedings{{{key},\n",
    "  author = {{{authors}}},\n",
    "  booktitle = {{{booktitle}}},\n",
    "  title = {{{title}}},\n",
    "  venue = {{{venue}}},\n",
    "  eventdate = {{{eventdate}}},\n",
    "  month = {{{month}}},\n",
    "  year = {{{year}}},\n",
    "  openreview = {{{ee}}},\n",
    "  bibtex_show = {{true}},\n",
    "  ABBR = {{{conf_abbr}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "def format_article(entry):\n",
    "    title = entry.get('title', 'Unknown')\n",
    "    authors = entry.get('author', 'Unknown Author')\n",
    "    year = entry.get('year', '????')\n",
    "    journal = entry.get('journal', '')\n",
    "    month = '7'\n",
    "    abbr = journal.split()[0].upper() if journal else \"JOUR\"\n",
    "    key = f\"{authors.split(' and ')[0].split()[-1]}{year}{extract_first_word(title)}\"\n",
    "\n",
    "    return f\"\"\"@article{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  journal = {{{journal}}},\n",
    "  month = {{{month}}},\n",
    "  year = {{{year}}},\n",
    "  bibtex_show = {{true}},\n",
    "  ABBR = {{{abbr}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "def format_misc(entry):\n",
    "    title = entry.get('title', 'Unknown')\n",
    "    authors = entry.get('author', 'Unknown Author')\n",
    "    year = entry.get('year', '????')\n",
    "    month = '7'\n",
    "    key = f\"{authors.split(' and ')[0].split()[-1]}{year}{extract_first_word(title)}\"\n",
    "    return f\"\"\"@misc{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  month = {{{month}}},\n",
    "  year = {{{year}}},\n",
    "  bibtex_show = {{true}},\n",
    "  ABBR = {{MISC}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "file = set()\n",
    "def process_entry(entry):\n",
    "    title = entry.get('title', '')\n",
    "    print(entry.get(\"type\" , \"\"))\n",
    "    file.add(entry.get(\"type\" , \"\"))\n",
    "    if 'journal' in entry:\n",
    "        return 'article', format_article(entry)\n",
    "    match_info = fetch_dblp_match_info(title)\n",
    "    if match_info:\n",
    "        return 'inproceedings', format_inproceedings_custom(entry, match_info)\n",
    "    return 'misc', format_misc(entry)\n",
    "\n",
    "def process_bib_file(input_file='css.bib', output_file='converted.bib'):\n",
    "    with open(input_file, 'r', encoding='utf-8') as bibtex_file:\n",
    "        bib_database = bibtexparser.load(bibtex_file)\n",
    "\n",
    "    print(f\"📚 Loaded {len(bib_database.entries)} entries from {input_file}\")\n",
    "    entries = bib_database.entries\n",
    "\n",
    "    # Run in parallel\n",
    "    print(\"🚀 Processing entries with DBLP in parallel...\")\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(executor.map(process_entry, entries))\n",
    "\n",
    "    # # Collect formatted BibTeX\n",
    "    # articles, inprocs, miscs = [], [], []\n",
    "    # for typ, entry in results:\n",
    "    #     if typ == 'article':\n",
    "    #         articles.append(entry)\n",
    "    #     elif typ == 'inproceedings':\n",
    "    #         inprocs.append(entry)\n",
    "    #     else:\n",
    "    #         miscs.append(entry)\n",
    "\n",
    "    # with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    #     if inprocs:\n",
    "    #         f.write(\"% === INPROCEEDINGS ===\\n\\n\")\n",
    "    #         f.writelines(inprocs)\n",
    "    #     if articles:\n",
    "    #         f.write(\"% === ARTICLES ===\\n\\n\")\n",
    "    #         f.writelines(articles)\n",
    "    #     if miscs:\n",
    "    #         f.write(\"% === MISC ===\\n\\n\")\n",
    "    #         f.writelines(miscs)\n",
    "\n",
    "    # print(f\"\\n✅ Written to {output_file}: {len(inprocs)} inproceedings, {len(articles)} articles, {len(miscs)} misc\")\n",
    "\n",
    "# Run the converter\n",
    "process_bib_file('css.bib', 'converted.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188867b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted 234 entries and saved to papers_css.bib\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import difflib\n",
    "import urllib.parse\n",
    "import requests\n",
    "import bibtexparser\n",
    "from bibtexparser.bparser import BibTexParser\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import defaultdict\n",
    "\n",
    "def sanitize_key(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n",
    "    return re.sub(r'\\W+', '', text)\n",
    "\n",
    "def extract_first_word(title):\n",
    "    words = re.findall(r'\\b\\w+\\b', title)\n",
    "    return sanitize_key(words[0]) if words else \"Untitled\"\n",
    "\n",
    "def guess_bibtex_type(entry_type):\n",
    "    entry_type = (entry_type or \"\").strip().lower()\n",
    "    if entry_type == \"journal article\":\n",
    "        return \"article\"\n",
    "    elif entry_type == \"conference paper\":\n",
    "        return \"inproceedings\"\n",
    "    elif entry_type == \"book\":\n",
    "        return \"book\"\n",
    "    elif entry_type == \"book chapter\":\n",
    "        return \"inbook\"\n",
    "    elif entry_type in {\"preprint\", \"patent\", \"abstract\", \"\"}:\n",
    "        return \"misc\"\n",
    "    else:\n",
    "        return \"misc\"\n",
    "\n",
    "def fetch_dblp_match_info(title, max_hits=5, threshold=0.85):\n",
    "    q = urllib.parse.quote(title)\n",
    "    url = f\"https://dblp.org/search/publ/api?q={q}&h={max_hits}&format=json\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10).json()\n",
    "        hits = resp.get('result', {}).get('hits', {}).get('hit', [])\n",
    "        if not hits:\n",
    "            return None\n",
    "        best_match = max(hits, key=lambda h: difflib.SequenceMatcher(None, h['info'].get('title', '').lower(), title.lower()).ratio())\n",
    "        score = difflib.SequenceMatcher(None, best_match['info'].get('title', '').lower(), title.lower()).ratio()\n",
    "        return best_match['info'] if score >= threshold else None\n",
    "    except Exception as e:\n",
    "        print(f\"\\U0001f50d DBLP lookup failed for '{title}': {e}\")\n",
    "    return None\n",
    "\n",
    "def format_entry(entry, dblp_info=None):\n",
    "    entry_type = guess_bibtex_type(entry.get('type', ''))\n",
    "    title = entry.get('title', 'Unknown Title')\n",
    "    authors = entry.get('author', 'Unknown Author')\n",
    "    year = str(entry.get('year', '????'))\n",
    "    first_author = authors.split(' and ')[0].split()[-1]\n",
    "    first_word = extract_first_word(title)\n",
    "    key = f\"{first_author}{year}{first_word}\"\n",
    "\n",
    "    if entry_type == \"article\":\n",
    "        journal = entry.get('journal', '')\n",
    "        return year, f\"\"\"@article{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  journal = {{{journal}}},\n",
    "  year = {{{year}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "    elif entry_type == \"inproceedings\":\n",
    "        if year == \"????\" and dblp_info:\n",
    "            year = dblp_info.get('year', '????')\n",
    "\n",
    "        venue = dblp_info.get('venue', '') if dblp_info else ''\n",
    "        booktitle = entry.get('journal', '') if dblp_info else venue\n",
    "        ee = dblp_info.get('ee', '') if dblp_info else ''\n",
    "        conf_abbr = dblp_info.get('key', '').split('/')[1].upper() if dblp_info and '/' in dblp_info.get('key', '') else 'CONF'\n",
    "        eventdate = f\"{year}-07-19\"\n",
    "        return year, f\"\"\"@inproceedings{{{key},\n",
    "  author = {{{authors}}},\n",
    "  booktitle = {{{booktitle}}},\n",
    "  title = {{{title}}},\n",
    "  venue = {{{venue}}},\n",
    "  eventdate = {{{eventdate}}},\n",
    "  month = {{7}},\n",
    "  year = {{{year}}},\n",
    "  openreview = {{{ee}}},\n",
    "  bibtex_show = {{true}},\n",
    "  ABBR = {{{conf_abbr}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "    elif entry_type == \"book\":\n",
    "        publisher = entry.get('publisher', '')\n",
    "        return year, f\"\"\"@book{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  publisher = {{{publisher}}},\n",
    "  year = {{{year}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "    elif entry_type == \"inbook\":\n",
    "        booktitle = entry.get('booktitle', '')\n",
    "        pages = entry.get('pages', '')\n",
    "        return year, f\"\"\"@inbook{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  booktitle = {{{booktitle}}},\n",
    "  pages = {{{pages}}},\n",
    "  year = {{{year}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "    else:\n",
    "        return year, f\"\"\"@misc{{{key},\n",
    "  author = {{{authors}}},\n",
    "  title = {{{title}}},\n",
    "  year = {{{year}}}\n",
    "}}\\n\"\"\"\n",
    "\n",
    "def process_entry(entry):\n",
    "    entry_type = guess_bibtex_type(entry.get('type', ''))\n",
    "    entry\n",
    "\n",
    "def convert_bib_file(input_bib, output_bib):\n",
    "    with open(input_bib, 'r', encoding='utf-8') as f:\n",
    "        bib_database = BibTexParser(common_strings=True).parse_file(f)\n",
    "        entries = bib_database.entries\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        formatted = list(executor.map(process_entry, entries))\n",
    "\n",
    "    sorted_by_year = defaultdict(list)\n",
    "    for year, entry in formatted:\n",
    "        sorted_by_year[year].append(entry)\n",
    "\n",
    "    with open(output_bib, 'w', encoding='utf-8') as f:\n",
    "        for year in sorted(sorted_by_year.keys(), reverse=True):\n",
    "            f.write(f\"% === {year} ===\\n\\n\")\n",
    "            for entry in sorted_by_year[year]:\n",
    "                f.write(entry + '\\n')\n",
    "\n",
    "    print(f\"✅ Converted {len(entries)} entries and saved to {output_bib}\")\n",
    "\n",
    "# Example usage:\n",
    "convert_bib_file(\"filtered_css.bib\", \"papers_css.bib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56338454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
